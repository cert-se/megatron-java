# Global config file for Megatron (dev).
#
# Note: A global property may be overridden by a job-type propery.
# Job-type properties are defined in the job-type directory, one file
# for each job-type, e.g. "shadowserver-ddos.properties". 


##
# General
##

# Filename for log4j config-file.
general.log4jConfigFile=conf/dev/log4j.properties

# Directory for log files (must correspond to directory in log4j.properties).
general.logDir=log

# Directory for job-type properties files.
general.jobTypeConfigDir=conf/job-type

# Slurp directory. Input files in this directory will be processed automagically. 
general.slurpDir=slurp

# Output directory for export files. May be overridden by "--output-dir". 
general.outputDir=tmp/export

# Directory for temporary files.
general.tmpDir=tmp/work

# Character-set for log files, e.g. "ISO-8859-1", "UTF-8".
general.inputCharSet=UTF-8

# Map a filename to a job-type. Files dropped in the slurp directory must have
# a mapping in this list. Format: <reg-exp to match filename>=job-type 
# Example: 2009-06-08-drone-report-se.log --> shadowserver-drone
general.filenameMapperList.0=^\d{4}+-\d\d-\d\d-drone-report-\w\w\.(?:log|csv)=shadowserver-drone
# Example: 2009-06-08-ddos-report-se.log|2011-01-18-botnet_ddos-sweden-geo.csv --> shadowserver-ddos
general.filenameMapperList.1=^\d{4}+-\d\d-\d\d-(?:ddos-report|botnet_ddos)-.*?\.(?:log|csv)=shadowserver-ddos
# Example: 2009-06-07-sinkhole-http-drone-report-se.log|2011-01-18-sinkhole_http_drone-sweden-geo.csv --> shadowserver-sinkhole-http-drone
general.filenameMapperList.2=^\d{4}+-\d\d-\d\d-sinkhole[-_]http[-_]drone-.*?\.(?:log|csv)=shadowserver-sinkhole-http-drone
# Example: whois-cymru-verbose-with-timestamps-file1.log --> whois-cymru-verbose-with-timestamps
general.filenameMapperList.3=^whois-cymru-verbose-with-timestamps.*\.log=whois-cymru-verbose-with-timestamps
# Example: whois-cymru-verbose-file1.log --> whois-cymru-verbose
general.filenameMapperList.4=^whois-cymru-verbose.*\.log=whois-cymru-verbose
# Example: ip-sorbs-http.dnsbl.sorbs.net__2009-09-24_075224.log --> rbl-ip-range
general.filenameMapperList.5=^ip-sorbs-.*\.log=rbl-ip-range
# Example: url-sorbs-badconf.rhsbl.sorbs.net__2009-09-24_075222.log --> rbl-hostname
general.filenameMapperList.6=^url-sorbs-.*\.log=rbl-hostname
# Example: ip-spamcannibal-bl.spamcannibal.org.in.cmb.rbl__2009-09-24_075615.log --> rbl-ip-range
general.filenameMapperList.7=^ip-spamcannibal-.*\.log=rbl-ip-range
# Example: ip-spamhaus-pbl__2009-09-24_073601.log --> rbl-ip-range
general.filenameMapperList.8=^ip-spamhaus-.*\.log=rbl-ip-range
# Example: ip-uceprotect-dnsbl-1.uceprotect.net__2009-09-24_075747.log --> rbl-ip-range
general.filenameMapperList.9=^ip-uceprotect-.*\.log=rbl-ip-range
# Example: syslog-spamcannibal-honeypot.last__2009-11-09_072914.log --> syslog-ip-plus-host
general.filenameMapperList.10=^syslog-spamcannibal-.*\.log=rbl-syslog-ip-plus-host
# Example: ip-dshield-asdetailsascii.html__2009-12-17_093148.log --> dshield
general.filenameMapperList.11=^.*dshield-asdetailsascii.*\.log=dshield
# Example: ip-flowing-aucert_infected_ipsitic_id_1958.log --> ip-flowing
general.filenameMapperList.12=^ip-flowing.*\.log=ip-flowing
# Example: 2009-12-22-conficker-http-drone-report-se.csv --> shadowserver-conficker-http-drone
general.filenameMapperList.13=^\d{4}+-\d\d-\d\d-conficker-http-drone-report-\w\w\.(?:log|csv)=shadowserver-conficker-http-drone
# Example: ip-sshbl-date.txt__2010-01-10_093250.log --> sshbl
general.filenameMapperList.14=^ip-sshbl.*\.log=sshbl
# Example: ip-psbl-psbl.txt__2010-01-14_101035.log --> rbl-ip-range
general.filenameMapperList.15=^ip-psbl.*\.log=rbl-ip-range
# Example: 2009-06-08-proxy-report-se.log|2011-02-20-botnet_proxy-sweden-geo.csv --> shadowserver-proxy
general.filenameMapperList.16=^\d{4}+-\d\d-\d\d(?:-proxy-report-\w\w|-botnet_proxy-.+?-geo)\.(?:log|csv)=shadowserver-proxy
# Example: inteco-cert-fast-flux-2009-06-08.log --> inteco-cert-fast-flux
general.filenameMapperList.17=^inteco-cert-fast-flux.*\.(?:log|txt)=inteco-cert-fast-flux
# Example: sunet-portscan-2009-06-08.log --> sunet-portscan
general.filenameMapperList.18=^sunet-portscan.*\.(?:log|txt)=sunet-portscan
# Example: 2010-01-20-sandbox-url-report-se.log|2011-01-18-cwsandbox_url-sweden-geo.csv --> shadowserver-sandbox-url
general.filenameMapperList.19=^\d{4}+-\d\d-\d\d-(?:sandbox-url-report|cwsandbox_url)-.*?\.(?:log|csv)=shadowserver-sandbox-url
# Example: 2009-11-29-scan-report-nl.csv --> shadowserver-scan
general.filenameMapperList.20=^\d{4}+-\d\d-\d\d-scan-report-\w\w\.(?:log|csv)=shadowserver-scan
# Example: ctir-abuse-2010-02-01.log --> ctir-abuse
general.filenameMapperList.21=^ctir-abuse.*\.(?:log|txt)=ctir-abuse
# Example: ip-zeustracker-pushdo-20100218.log --> zeustracker-pushdo
general.filenameMapperList.22=^ip-zeustracker-pushdo.*\.log=zeustracker-pushdo
# Example: url-zeustracker-zeusdomain__2010-02-19_085233.log --> zeustracker-blocklist-domain 
general.filenameMapperList.23=^url-zeustracker-zeusdomain.*\.log=zeustracker-blocklist-domain
# Example: ip-zeustracker-zeusip__2010-02-19_085236.log --> zeustracker-blocklist-ip 
general.filenameMapperList.24=^ip-zeustracker-zeusip.*\.log=zeustracker-blocklist-ip
# Example: 2010-03-02-drone-report2-se.csv|2011-01-18-botnet_drone-sweden-geo.csv --> shadowserver-drone2
general.filenameMapperList.25=^\d{4}+-\d\d-\d\d-(?:drone-report2|botnet_drone)-.*?\.(?:log|csv)=shadowserver-drone2
# Example: url-spamhaus-dbl__2010-03-04_111643.log --> rbl-hostname
general.filenameMapperList.26=^url-spamhaus-.*\.log=rbl-hostname
# Example: ip-danger_rulez_sk-bruteforceblocker__2010-03-10_145109.log --> danger-rulez
general.filenameMapperList.27=^ip-danger_rulez_sk-bruteforceblocker.*\.log=danger-rulez
# Example: url-phishtank-data__2010-03-29_103903.log --> phishtank
general.filenameMapperList.28=^url-phishtank-data.*\.log=phishtank
# Example: url-malwarepatrol__2010-03-29_103903.log --> malwarepatrol
general.filenameMapperList.29=^url-malwarepatrol.*\.log=malwarepatrol
# Example: url-blade_defender-eval_lab__2010-03-29_063604.log --> blade-defender
general.filenameMapperList.30=^url-blade_defender-eval_lab.*\.log=blade-defender
# Example: url-clean-mx-phishing__2010-04-06_143840.log --> clean-mx-phishing
general.filenameMapperList.31=^url-clean-mx-phishing.*\.log=clean-mx-phishing
# Example: url-clean-mx-viruses__2010-04-07_065212.log --> clean-mx-viruses
general.filenameMapperList.32=^url-clean-mx-viruses.*\.log=clean-mx-viruses
# Example: ip-dronebl-buildzone__2010-11-19_063003.log --> dronebl
general.filenameMapperList.33=^ip-dronebl-buildzone.*\.log=dronebl
# Example: vs-db__2010-11-19_063003.log --> vs-db
general.filenameMapperList.34=^vs-db.*\.log=vs-db
# Example: xssed__2010-11-19_063003.log --> xssed
general.filenameMapperList.35=^xssed.*\.log=xssed
# Example: 2010-10-27-spam-url-report-se.log|2011-01-13-spam_url-sweden-geo.csv --> shadowserver-spam-url
general.filenameMapperList.36=^\d{4}+-\d\d-\d\d-spam[-_]url-.*?\.(?:log|csv)=shadowserver-spam-url
# Example: 2010-11-06-cc-ip-report-se.log|2011-01-18-cc_ip-sweden-geo.csv --> shadowserver-cc-ip
general.filenameMapperList.37=^\d{4}+-\d\d-\d\d-cc[-_]ip-.*?\.(?:log|csv)=shadowserver-cc-ip
# Example: malc0de__2010-11-19_063003.log --> malc0de
general.filenameMapperList.38=^malc0de.*\.log=malc0de
# Example: google__2011-05-12_090732.log --> google
general.filenameMapperList.39=^google.*\.log=google
# Example: bing__2011-05-12_090732.log --> bing
general.filenameMapperList.40=^bing.*\.log=bing
# Example: malc0de__2012-01-16_073315.log --> malc0de
general.filenameMapperList.41=^malc0de__.*\.log=malc0de
# Example: ip-autoshun-sshscanners__2012-01-16_102814.log --> autoshun
general.filenameMapperList.42=^ip-autoshun-sshscanners__.*\.log=autoshun
# Example: ip-chaley-ssh_dict__2012-01-16_062750.log --> chaley-ssh-dict
general.filenameMapperList.43=^ip-chaley-ssh_dict__.*\.log=chaley-ssh-dict
# Example: ip-infiltrated-net-blacklist__2012-01-16_102815.log --> infiltrated-net-blacklist
general.filenameMapperList.44=^ip-infiltrated-net-blacklist__.*\.log=infiltrated-net-blacklist
# Example: ip-stopforumspam-all__2012-01-16_062801.log --> stopforumspam
general.filenameMapperList.45=^ip-stopforumspam-all__.*\.log=stopforumspam
# Example: ip-emerging_compromised__20120126-1020.txt --> emerging-compromised
general.filenameMapperList.46=^ip-emerging_compromised__.*\.txt=emerging-compromised
# Example: url-ikyon-badurls__2012-03-23_142655.log --> ikyon
general.filenameMapperList.47=^url-ikyon-badurls__.*\.log=ikyon
# Example: urlquery__20130214-120206-4.log --> urlquery
general.filenameMapperList.48=^urlquery__.*\.log=urlquery-mail


# Whois server. Used for example by --update-netname (NetnameUpdater).
general.whoisServer=whois.ripe.net

# Priority equals or above this threshold is considered "high priority".
# A notification email may be sent if high priority entries exists in a job. 
general.highPriorityNotification.threshold=40

# Issue warning if one timestamp in the input file is older than this max age (given in seconds).
# Use -1 to turn off warning. 1 week=7*24*60*60=604800
general.timestampWarning.maxAge=604800

# Print progress to console using this specified interval (given in seconds).
general.printProgressInterval=15

# What to do if file already processed (MD5-hash exists in db)?
# Values: error|skip|rerun
general.fileAlreadyProcessedAction=error


##
# GeoIP
##

# Filename for the GeoIP Country database.
geoIp.countryDatabaseFile=conf/geoip-db/GeoIP.dat

# Filename for the GeoIP ASN database.
geoIp.asnDatabaseFile=conf/geoip-db/GeoIPASNum.dat

# Filename for the GeoIP City database (contains latitude/longitude, country, city etc.).
geoIp.cityDatabaseFile=conf/geoip-db/GeoLiteCity.dat

# If true, uses the city database instead of the country database.
# Set to true if the commercial city database is used.
geoIp.useCityDatabaseForCountryLookups=false


##
# dnsjava
##

# Use dnsjava class library? dnsjava have much better performance than the standard JDK implementation.  
dnsJava.useDnsJava=true

# If true, SimpleResolver will be used which will use only one DNS server.
# If false, ExtendedResolver will be used which uses multiple DNS servers.
# SimpleResolver is of course faster, but less reliable. 
dnsJava.useSimpleResolver=true

# Comma separated list of DNS servers. If undefined, the machine's default DNS
# servers will be used (as defined in e.g. /etc/resolv.conf).
#dnsJava.dnsServers=8.8.4.4,8.8.8.8

# Amount of seconds to wait for a response before giving up.
dnsJava.timeOut=2


##
# Database
##

# Note: Remember to change "hibernate.cfg.xml" if anything in this section is modified.

db.username=megatron
db.password=megatron

# local
db.name=megatron
db.server=127.0.0.1
db.port=3306

db.jdbc.url=jdbc:mysql://{db.server}:{db.port}/{db.name}
db.jdbc.driverClassName=com.mysql.jdbc.Driver


##
# System Data Import
##

# File that contains the system definitions and contact data
import.dataFile=conf/dev/systemdata.txt


##
# BGP Table Import
##

# File that contains the BGP table dump.
bgp.importFile=test-data-bronto/bgp-table-full.txt

# Name-Value list (BGP prefix-ASN) with prefixes that are missing in the BGP table. 
# TODO Change on install 
# Sitic AS41884
bgp.hardCodedPrefixes.0=192.121.218.0/24=41884


##
# Export
##

# Directory for export templates.
export.templateDir=conf/template/export

# Filename to file templates. "headerFile" and "footerFile" may be undefined, but
# "rowFile" is mandatory. The directory is specified in "export.templateDir".
#export.headerFile=
export.rowFile=debug_row.txt
#export.footerFile=

# Character-set for export files, e.g. "ISO-8859-1", "UTF-8".
export.charSet=UTF-8

# Date-and time format in export. Will also be used in mail templates.
# Format reference: http://java.sun.com/j2se/1.5.0/docs/api/java/text/SimpleDateFormat.html
# Example: yyyy-MM-dd HH:mm:ss z --> 2009-07-02 11:39:41 UTC, dd/MMM/yyyy:HH:mm:ss Z --> 07/Jul/2009:11:04:34 +0000
export.timestampFormat=yyyy-MM-dd HH:mm:ss z

# List of attribute value rewriters, e.g. rewrites the url from "http" to "hxxp".
# Attribute values are rewritten just before they are added to the template.    
# 
# Syntax: <attribute name>:<from>--><replace with> 
# Note 1: Spaces are not trimmed from property above.
# Note 2: Both file- and mail export are affected by this property. 
#
# See also "parser.rewriters" (will store rewrites in db)
# 
# This example rewrites URLs from "http" to "hxxp" and mask IP addresses:  
#export.rewriters.0=url:(?i)(h)tt(ps{0,1}://.+)-->$1xx$2
#export.rewriters.1=ipAddress:(\d{1,3})\.(\d{1,3})\.\d{1,3}\.\d{1,3}-->$1.$2.x.x

# Converts job-type names (format: from=to). Use this property when an internal
# name should not be known public. Job-type names can be used in attachment. 
# Example:
#export.jobTypeNameMapper.0=nda-spam-report=spam-report
#export.jobTypeNameMapper.1=nda-bot-report=bot-report


##
# Mail
##

# SMTP hosts
# TODO Change on install
mail.smtpHost.0=smtp01.example.org
mail.smtpHost.1=smtp02.example.org

# Enable debug logging in JavaMail? 
mail.debug=false

# Defult from-address.
# TODO Change on install
mail.fromAddress=Ticket <ticket@example.org>

# Defult to-addresses. Use comma as separator, e.g. "foo@example.org, bar@example.org".
# TODO Change on install
mail.toAddresses=megatron@example.org

# Defult reply to-addresses (optional). Use comma as separator, e.g. "foo@example.org, bar@example.org".
# TODO Change on install
#mail.replyToAddresses=Ticket <ticket@example.org>

# Email addresses to which a copy of every abuse mail is sent to, e.g. "megatron-archive@example.org".
# TODO Change on install
mail.archiveBccAddresses=megatron-archive@example.org

# Email addresses for the mail job summary, e.g. "megatron@example.org".
# TODO Change on install
mail.mailJobSummary.toAddresses=megatron@example.org

# Email addresses for the notification that log job contains high priority entries, e.g. "megatron@example.org".
# TODO Change on install
mail.highPriorityNotification.toAddresses=megatron@example.org

# Use HTML mail? If true, "Content-type" will be set to "text/html". Otherwise is "text/plain" used.
mail.htmlMail=false

# Period in seconds for which an IP is quarantined to avoid that multiple emails are
# sent regarding the same IP number. Set to 0 to turn off quarantine.
mail.ipQuarantinePeriod=345600

# Template for mail subject (default and english).
# TODO Change on install
mail.subjectTemplate=Säkerhetsmeddelande från CERT-SE [CERT-SE #$rtirId]
mail.subjectTemplate.en=Security Notification from CERT-SE [CERT-SE #$rtirId]

# Template for subject in mail job summary mail.
# TODO Change on install
mail.mailJobSummary.subjectTemplate=Megatron: Mail job #$mailJobId finished [CERT-SE #$rtirId]

# Directory for mail templates.
mail.templateDir=conf/template/mail

# Default language for mail templates, e.g. "en". 
mail.defaultLanguageCode=sv

# Filename to templates for mail. If property is undefined or empty, the section is skipped.
# The directory is specified in "mail.templateDir".
# Body
#mail.headerFile=
mail.rowFile=debug_row.txt
mail.footerFile=general_footer.txt
# Attachment
mail.attachmentHeaderFile=attachment_header.txt
mail.attachmentRowFile=attachment_row.txt
#mail.attachmentFooterFile=

# Filename for attachment
mail.attachmentName=abuse-report.csv

# Raise error if debug mail templates are used. 
mail.raiseErrorForDebugTemplate=false


##
# RSS
##

# Class name for RSS implementation.
rss.factoryClassName=se.sitic.megatron.rss.rome.RomeRssFactory

# Format for RSS file. The value depends on which RSS class library is used,
# and for Rome the following values are applicable:
#   * Recommended: rss_0.94, rss_1.0, rss_2.0, atom_0.3, atom_1.0
#   * Untested:    rss_0.9, rss_0.91N, rss_0.91U, rss_0.92, rss_0.93 
# ('N' stands for Netscape, and 'U' for Userland.)
rss.format=rss_2.0

# -- Job RSS: Feed for completed log- and mail jobs.

# Is writing to job feed enabled? If false, no file will be created.
rss.job.enabled=true

# Filename for RSS export.
rss.job.file=tmp/rss/megatron-jobs.xml

# Title of RSS.
rss.job.content.title=Megatron: Completed Log- and Mail Jobs
   
# Url of RSS (will probably be rendered by the RSS reader as a link for the title).
# TODO Change on install
rss.job.content.link=http://www.example.org/

# Description of RSS.
rss.job.content.description=This RSS have been generated by Megatron. 

# Author of RSS.
rss.job.content.author=Megatron

# Copyright of RSS
rss.job.content.copyright=Copyright (c) 2014 

# Max number of items in RSS file? A value of -1 means "no limit".
rss.job.maxNoOfItems=50

# Time in minutes to keep an item in the RSS file. A value of -1 means "keep forever".
rss.job.itemExpireTimeInMinutes=-1

# -- Stats RSS: Statistics generated from the database (--create-rss)
rss.stats.file=tmp/rss/megatron-stats.xml
rss.stats.content.title=Megatron: Statistics
# TODO Change on install
rss.stats.content.link=http://www.example.org/
rss.stats.content.description=This RSS have been generated by Megatron. 
rss.stats.content.author=Megatron
rss.stats.content.copyright=Copyright (c) 2014
#rss.stats.maxNoOfItems=60
#rss.stats.itemExpireTimeInMinutes=-1


##
# Report
##

# List of report class names. Will be excuted by the "--create-xml" switch.
report.classNames.0=se.sitic.megatron.report.StatisticsXmlReportGenerator
report.classNames.1=se.sitic.megatron.report.GeolocationJsonReportGenerator

# Output directory for report files.
report.outputDir=tmp/report

# Directory for report templates.
report.templateDir=conf/template/report

# -- StatisticsXmlReportGenerator: Creates XML files with overview statistics.
# No. of weeks in the statistics report
report.statistics.noOfWeeks=5

# -- GeolocationJsonReportGenerator: Creates JSON files with geolocation data.
# No. of weeks in the geolocation report (GeolocationJsonReportGenerator)
report.geolocation.noOfWeeks=4

# Generate internal report with e.g. IP addresses? 
report.geolocation.generateInternalReport=false

# Number of entries in the city report 
report.geolocation.noOfEntriesInCityReport=20

# Comma separated list of jobs to exclude (use value in "job_type.name").
report.geolocation.jobTypeKillList=default

# Comma separated list of organization types to exclude (use value in "prio.name").
# TODO Change on install
report.geolocation.organizationTypeKillList=Sitic, CERT-SE

# Converts organization type names (format: from=to)
report.geolocation.organizationTypeNameMapper.0=-=Miscellaneous Organizations

# -- OrganizationReportGenerator: Emails a report to organizations with log entries for a certain period.
# See "report-organization.properties" for more information.
# Include log entries with a create time within the last no. of hours (rounded to even hour)
report.organization.noOfHours=24

# List of job-types to include in the report (use value in "job_type.name").
# Example:
#report.organization.jobTypes.0=shadowserver-drone2
#report.organization.jobTypes.1=shadowserver-sinkhole-http-drone

# Organizations that will receive a report (use value in "organization.id")
# Example
# 1234 ISP 1
#report.organization.recipients.0=1234
# 1235 ISP 2
#report.organization.recipients.1=1235


##
# Filters
##

# Filter can be added before each step in the workflow. Each entry is a list of filters. Example:
# filter.preLineProcessor.classNames.0=se.sitic.megatron.filter.LineNumberFilter
# filter.preStorage.classNames.0=se.sitic.megatron.filter.CountryCodeFilter
# filter.preStorage.classNames.1=se.sitic.megatron.filter.AsnFilter
# filter.preMail.classNames.0=se.sitic.megatron.filter.PriorityFilter
# filter.preDecorator.classNames.0=se.sitic.megatron.filter.OccurrenceFilter
#  
# Two types of filters exists:
#   - ILineFilter: before parsing
#   - ILogEntryFilter: after parsing   

#filter.preLineProcessor.classNames.0=

#filter.preParser.classNames.0=

#filter.preDecorator.classNames.0=

#filter.preStorage.classNames.0=

#filter.preExport.classNames.0=

filter.preMail.classNames.0=se.sitic.megatron.filter.PriorityFilter

# -- RegExpLineFilter: Filter log lines using regular expressions. 
# Note: Only one of the property excludeRegExp or includeRegExp can be defined -- not both.

# Lines that matches this regular expression are filtered out. All other lines are included.
# The following example filters out comments prefixed with "#" or ";": 
#filter.regExpLineFilter.excludeRegExp=^\s*?(#|;)

# Lines that matches this regular expression are included. All other lines are filtered out. 
# The following example includes valid whois lines:
#filter.regExpLineFilter.includeRegExp=^\d+\s+\|

# -- LineNumberFilter: Filter log lines using intervals of line numbers. 
# Note: Only one of the property excludeIntervals or includeIntervals can be defined -- not both.

# Comma-separated list of line number intervals to filter out. 
# The following example filters out the first 10 lines plus lines 80-100:
#filter.lineNumberFilter.excludeIntervals=-10, 80-100

# Comma-separated list of line number intervals to include. 
# The following example includes the first 100 lines (the rest is filtered out):
#filter.lineNumberFilter.includeIntervals=-100

# -- PriorityFilter: Filter log entries using priority in matched organization. 
# Note: Requires that organization matcher have been executed.

# Comma-separated list of priority intervals to include. May be overridden by "--prio". 
# The following line includes log entries with a priority >= 70 (the rest is filtered out):
filter.priorityFilter.includeIntervals=45-

# -- CountryCodeFilter: Filter log entries using the country code and TLD in the hostname.
# Note: Only one of the property excludeCountryCodes or includeCountryCodes can be defined -- not both.

# Comma-separated list of country codes and TLDs to exclude.
# The following example excludes log entries for SE and unknown. All other lines are included.
#filter.countryCodeFilter.excludeCountryCodes=SE, -

# Comma-separated list of country codes and TLDs to include.
# The following example includes log entries for scandinavia and .info (the rest is filtered out):
#filter.countryCodeFilter.includeCountryCodes=SE, FI, NO, DK, info 

# Which organization to filter? Values: "primary", "secondary" (e.g. DDoS victims), or "both".
filter.countryCodeFilter.organizationToFilter=both

# -- AsnFilter: Filter log entries using the AS number.
# Note: Only one of the property excludeAsNumbers or includeAsNumbers can be defined -- not both.

# Comma-separated list of AS numbers to exclude.
# The following example excludes log entries for Bahnhof, Tele 2 and unknown. All other lines are included.
#filter.asnFilter.excludeAsNumbers=8473, 1257, -

# Comma-separated list of AS numbers to include.
# The following example includes log entries for Port 80 (the rest is filtered out):
#filter.asnFilter.includeAsNumbers=39369

# Which organization to filter? Values: "primary", "secondary" (e.g. DDoS victims), or "both".
filter.asnFilter.organizationToFilter=both

# -- OrganizationFilter: Filter out log entries that does not match an organization.

# Match IP-address, hostname, or ASN against the contact database?
# If all three are false, no lookups using OrganizationMatcherDecorator will be done.
# Use this option when OrganizationMatcherDecorator already have been executed.
filter.organizationFilter.matchIpAddress=true
filter.organizationFilter.matchHostname=true
filter.organizationFilter.matchAsn=true

# -- AttributeFilter: Filter log entries by matching an attribute to a regular expression.
# Note: Only one of the property excludeRegExp or includeRegExp can be defined -- not both.

# Attribute (without the "$"-prefix), e.g. "ipAddress", "url", "hostname", "hostname2", "logTimestamp", 
# "organizationName", "originalLogEntry", "additionalItem_httpStatusCode", or "freeText0". 
#filter.attributeFilter.attributeName=url

# Log entries with an attribute value that matches this regular expression are filtered out. All other entries are included.
# The following example filters out ftp URLs (using url): 
#filter.attributeFilter.excludeRegExp=^ftp://

# Log entries with an attribute value that matches this regular expression are included. All other lines are filtered out.
# The following example includes only GET requests (using originalLogEntry): 
#filter.attributeFilter.includeRegExp=\"GET\s

# -- OccurrenceFilter: Filter log entries by occurrence, e.g. "include first 20 matches of the same IP address" or
# "include log entries with more than 10 occurrences of the same URL". 
# Note: Only one of the property excludeIntervals or includeIntervals can be defined -- not both.

# Which attribute to count? Can be a comma separated list of attributes (values are concatenated), but 
# most of the time just one attribute. Remove "$"-prefix from attribute, e.g. "ipAddress", "url", 
# "hostname", "hostname2", "logTimestamp", "organizationName", "originalLogEntry", 
# "additionalItem_httpStatusCode",or "freeText0".
#filter.occurrenceFilter.attributeNames=ipAddress

# Comma-separated list of occurrence intervals to filter out. 
# The following example includes the first 20 lines (the rest is filtered out):
#filter.occurrenceFilter.excludeIntervals=21-

# Comma-separated list of occurrence intervals to include. 
# The following example includes the first 20 lines (the rest is filtered out):
#filter.occurrenceFilter.includeIntervals=-20

# Is input file sorted (e.g. by IP address)?
# If true, only previous line will be kept in memory and matched.
# If false, all attribute values will kept in memory.   
filter.occurrenceFilter.fileSorted=false


##
# File Processor
##

# A file processor handles a whole file, e.g. executes an OS-command to 
# transform the input file. The following file processors are available:
#   - se.sitic.megatron.fileprocessor.OsCommandProcessor
#   - se.sitic.megatron.fileprocessor.DiffProcessor
#   - se.sitic.megatron.fileprocessor.XmlToRowFileProcessor

# List of class names for the file processor. May be undefined. 
#fileProcessor.classNames.0=se.sitic.megatron.fileprocessor.OsCommandProcessor
#fileProcessor.classNames.1=se.sitic.megatron.fileprocessor.DiffProcessor

# Delete temporary files created by a file processor? Default is "true", but
# when debugging it can be handy to keep temporary files.
fileProcessor.deleteTmpFiles=true

# -- OsCommandProcessor: Executes an OS command on the input file. 

# Command to execute in for OsCommandProcessor. Output is then fed into line processor, filters, etc. 
#fileProcessor.osCommandProcessor.command=cat $inputFile

# -- DiffProcessor: Diff current input file with the one in previous run, and filter out old lines.

# Diff command for DiffProcessor, which will filter out old log lines.
# In Windows, diffutils GnuWin32 can be used: from http://gnuwin32.sourceforge.net/packages/diffutils.htm
fileProcessor.diffProcessor.command="C:\Program Files\GnuWin32\bin\diff.exe" $oldFile $newFile
# Unix
#fileProcessor.diffProcessor.command=/usr/bin/diff $oldFile $newFile

# Directory to keep the old files, which will be diffed with the new ones.  
fileProcessor.diffProcessor.oldFilesDir=tmp/diff-processor-old-files

# Number of backup files to keep of old diff files. 
fileProcessor.diffProcessor.noOfBackupsToKeep=10

# -- XmlToRowFileProcessor: Converts an XML-file using a SAX-parser to a row oriented file.

# Start element of the record. Name of element that contains the elements to save. 
#fileProcessor.xmlToRowFileProcessor.startElement=entry

# Elements to save to the output file. Element values will be written in this order.  
#fileProcessor.xmlToRowFileProcessor.elementsToSave=id, first, last, md5, virusname, url, recent, response, ip, as, review, domain, country, email, inetnum, netname, descr, ns1, ns2

# Separator for values in the output file. Tab="\t".
fileProcessor.xmlToRowFileProcessor.outputSeparator=\t

# -- MultithreadedDnsProcessor: Makes DNS lookups and reverse lookups in several threads 
# to increase performance. Result is used by IpAddressDecorator and HostnameDecorator. 

# Number of threads. Minimum number of DNS requests: noOfThreads * dnsJava.timeOut
fileProcessor.multithreadedDnsProcessor.noOfThreads=100

# Do reverse DNS lookups?
# If true, regExpIp will be used. If false, regExpHostname will be used.
fileProcessor.multithreadedDnsProcessor.reverseDnsLookup=true

# Regular expression to extract IP addresses. May use groups, or not.
fileProcessor.multithreadedDnsProcessor.regExpIp=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}

# Regular expression to extract hostnames. May use groups, or not.
fileProcessor.multithreadedDnsProcessor.regExpHostname=(?i)https{0,1}://([^\s,]+)


##
# Line Processor
##

# A line processor merges or splits a line.

# Class name for the line processor. May be undefined. 
#lineProcessor.className=se.sitic.megatron.lineprocessor.LineMerger
#lineProcessor.className=se.sitic.megatron.lineprocessor.LineSplitter

# -- LineMerger: Merges lines using reg-exp.

# Merged line: line that matches startRegExp + lines in between + line that matches endRegExp. 
#lineProcessor.merger.startRegExp=
#lineProcessor.merger.endRegExp=

# Restart matching of block if startRegExp matches the last line?
# If false, matching will only restart when endRegExp matches. 
lineProcessor.merger.restartIfStartFound=true

# Separator for appended lines. Space is default if undefined. 
#lineProcessor.merger.separator=

# -- LineSplitter: Splits one line to several lines.
# Note: Only one of the property separatorRegExp or itemRegExp can be defined -- not both.

# One line for each item this regular expression is separating.
#lineProcessor.splitter.separatorRegExp=\t

# One line for each match of this regular expression. 
#lineProcessor.splitter.itemRegExp=.*?\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}

# Append original log row to splitted line?
lineProcessor.splitter.appendOriginalLogRow=false


##
# Decorators
##

# A decorator adds data to a log entry, e.g. country code. 
# The following decorators are available:
#   - se.sitic.megatron.decorator.CombinedDecorator (IP + ASN + Country code + Hostname)
#   - se.sitic.megatron.decorator.CountryCodeDecorator
#   - se.sitic.megatron.decorator.CountryCodeFromHostnameDecorator
#   - se.sitic.megatron.decorator.HostnameDecorator
#   - se.sitic.megatron.decorator.IpAddressDecorator
#   - se.sitic.megatron.decorator.AsnDecorator
#   - se.sitic.megatron.decorator.AsnGeoIpDecorator
#   - se.sitic.megatron.decorator.UrlToHostnameDecorator
#   - se.sitic.megatron.decorator.GeolocationDecorator

# List of class name for decorators to use.
decorator.classNames.0=se.sitic.megatron.decorator.CombinedDecorator

# List of class name for decorators applied before export.
# May be used by a "noisy" decorator, e.g. GeolocationDecorator produces data
# that we do not want to store in the database but we may want it in an export.   
#decorator.preExport.classNames.0=se.sitic.megatron.decorator.GeolocationDecorator

# List of class name for decorators applied before mail.
#decorator.preMail.classNames.0=se.sitic.megatron.decorator.GeolocationDecorator

# -- CombinedDecorator
# List of class name for CombinedDecorator to use.
decorator.combinedDecorator.classNames.0=se.sitic.megatron.decorator.IpAddressDecorator
decorator.combinedDecorator.classNames.1=se.sitic.megatron.decorator.AsnGeoIpDecorator
decorator.combinedDecorator.classNames.2=se.sitic.megatron.decorator.HostnameDecorator
decorator.combinedDecorator.classNames.3=se.sitic.megatron.decorator.CountryCodeFromHostnameDecorator
decorator.combinedDecorator.classNames.4=se.sitic.megatron.decorator.CountryCodeDecorator

# -- OrganizationMatcherDecorator
# Use organization matcher (finds organization for a log entry)? 
decorator.useOrganizationMatcher=true

# Match IP-address, hostname, or ASN against the contact database?
# Match only on ASN if upstream provider should be filtred out, 
# e.g. in the case of a DDoS.
decorator.organizationMatcher.matchIpAddress=true
decorator.organizationMatcher.matchHostname=true
decorator.organizationMatcher.matchAsn=true

# -- CountryCodeFromHostnameDecorator
# List of country codes to handle. If undefined or empty all country codes 
# extracted from the hostname will be assigned to the countryCode-field.
# If this property is set to "SE" and CountryCodeDecorator is used after
# CountryCodeFromHostnameDecorator, then all hostname ending with ".se" *and*
# IP addresses located in Sweden will set the countryCode-field to "SE".      
decorator.countryCodeFromHostnameDecorator.countryCodesToAdd=SE, NU

# -- AsnGeoIpDecorator
# If false, adds "asn" and "asn2" to "additionalItem_asn" and "additionalItem_asn2"
# instead of in LogEntry. Note: AsnDecorator can write to LogEntry and AsnGeoIpDecorator
# can write to both LogEntry and AdditionalItem.
decorator.asnGeoIpDecorator.useAsnInLogEntry=true

# Add AS name to additionalItem?
decorator.asnGeoIpDecorator.addAsName=false

# -- UrlToHostnameDecorator
# Use primary organization and assign the hostname field?
# If false, the hostname2 field will be assigned.  
decorator.urlToHostnameDecorator.usePrimaryOrg=true

# -- GeolocationDecorator
# Fields to add as additional items.
# Possible values: latitude, longitude, city, countryCode, countryName, region, postalCode, areaCode, metroCode
# Suffix with "2" for location of ipAddress2, e.g. "latitude2, longitude2, city2".  
decorator.geolocationDecorator.fieldsToAdd=latitude, longitude, city


##
# Parser
##

# Class name for parser implementation.
parser.className=se.sitic.megatron.parser.RegExpParser

# Maximum ratio of parse errors and total lines in file.
# Example: 0.2 means up to 20% of the lines may have parse errors. 
parser.parseErrorThreshold=0.20

# Maximum number of parse errors. Error raised only if both "parseErrorThreshold" 
# and "maxNoOfParseError" have been passed.   
parser.maxNoOfParseErrors=5

# Date-and time format for the logTimestamp-item. 
# Format reference: http://java.sun.com/j2se/1.5.0/docs/api/java/text/SimpleDateFormat.html
# Additional formats:
#   - epochInSec: Unix epoch in seconds.
#   - epochInMs: Unix epoch in milliseconds.
#   - windowsEpoch: the number of 100-nanoseconds intervals since Jan 1, 1601 UTC. Also
#     called "Windows NT time format", "18-digit Active Directory timestamp", or 
#     "Win32 FILETIME or SYSTEMTIME". Converter: http://www.epochconverter.com/ 
# Example: yyyy-MM-dd HH:mm:ss z --> 2009-07-02 11:39:41 UTC, dd/MMM/yyyy:HH:mm:ss Z --> 07/Jul/2009:11:04:34 +0000
parser.timestampFormat=yyyy-MM-dd HH:mm:ss z

# Prepend the unparsed logTimestamp field with current date (in the format yyyy-MM-dd)?
# Set to true, if the logTimestamp field contain time but not date. 
parser.addCurrentDateToTimestamp=false

# Time-zone to add to parsed time-stamp, e.g. "CET" or "GMT+01:00". 
# Comment out this property if time-zone is specified in the log file, or UTC is implicit used.
# Note: Summer time changes the time-zone. In Sweden, for example, CET (Central European Time) is 
# used in the winter, but CEST (Central European Summer Time) in the summer.
# More info: http://www.timeanddate.com/library/abbreviations/timezones/eu/cet.html
#parser.defaultTimeZone=GMT+01:00

# Check for unused variables in lineRegExp expression?
# Turn off if "$" is used in the regular expression. 
parser.checkUnusedVariables=true

# Remove leading and trailing whitespaces from parsed value.
parser.trimValue=false

# Remove specified enclosing characters from parsed value.
# The following example will remove double quotes from values, e.g. "foobar" --> foobar  
#parser.removeEnclosingCharsFromValue="

# List of attribute value rewriters, e.g. rewrites the url from "http" to "hxxp".
# Attribute values are rewritten just before they are converted to a log entry.    
# 
# Syntax: <attribute name>:<from>--><replace with> 
# Note 1: Spaces are not trimmed (from property value above).
# Note 2: IP addresses, ASNs, and ports can only be converted to an integer 
# value because it's stored in the database as an integer. However, this
# limitation is not present during export (see "export.rewriters").    
#
# See also "export.rewriters" (will not store rewrites to db)
# 
# This example rewrites URLs from "http" to "hxxp":  
#parser.rewriters.0=url:(?i)(h)tt(ps{0,1}://.+)-->$1xx$2

# Remove trailing whitespaces from line before processing it.
parser.removeTrailingSpaces=false

# Expand trailing zero octets in an IP range which is in the format of an 
# IP-address? If true, e.g. "202.131.0.0" will be expanded to "202.131.0.0/16". 
parser.expandIpRangeWithZeroOctets=false

# -- Items, that may be used in parser.lineRegExp and stored in the database.
# An item is specified by a regular expression. 
#
# Note: Java syntax is used in regular expression, which is the same as Perl-syntax
# with a few exceptions. This is described here (search for "Comparison to Perl 5"):   
# http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html
#
# Tip: Use an interactive regular expression tester and builder: 
#   * QuickREx (Windows): http://www.bastian-bergerhoff.com/eclipse/features/web/QuickREx/standalone.html
#   * Python Regular Expression Builder: http://freshmeat.net/projects/pyreb/
#
# The following embedded flag expressions are common:
#   ?i -- Enables case-insensitive matching.
#   ?s -- Enables dotall mode. In dotall mode, the expression . matches any character, including a line terminator.

# Timestamp in log line. 
# Note: Override this property for more control, e.g. "\d{4}-\d{2}-\d{2} \d{1,2}:\d{2}:\d{2} UTC" 
parser.item.logTimestamp=.*

# Primary host info, e.g. rogue host.
parser.item.ipAddress=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|
parser.item.hostname=.*
parser.item.port=\d*
parser.item.asn=\d*
parser.item.countryCode=\w{0,2}

# Secondary host info, e.g. victim.
parser.item.ipAddress2=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|
parser.item.hostname2=.*
parser.item.port2=\d*
parser.item.asn2=\d*
parser.item.countryCode2=\w{0,2}

# IP range. Formats: 192.121.218.4, 192.121.218.0/20, 192.121.218.0-255, 192.121.218.0-192.121.220.255, 192.121.x.x 
parser.item.ipRange=\d{1,3}\.(?:\d{1,3}|[xX])\.(?:\d{1,3}|[xX])\.(?:\d{1,3}|[xX])(?:-\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|-\d{1,3}|/\d{1,2}){0,1}

# URL in log line
parser.item.url=.*

# Free-text. Referenced in lineRegExp as $freeText0, $freeText1, ...  
# Example: parser.item.freeText0=.*
# parser.item.freeText.0=
# parser.item.freeText.1=
# parser.item.freeText.2=
# ...

# Additional untyped name-value items.
# The following example is referenced in lineRegExp as "$additionalItem_ftpUrl": 
#parser.item.additionalItem.ftpUrl=ftp://.*

# Regular expression that matches lines in file. Contains items that are 
# prefixed with "$", e.g. "$ipAddress", "$ipAddress2", "$url", "$freeText0", 
# "$freeText1", "$additionalItem_name", "$additionalItem_anotherName".
# Example: ^$asn\s*\|\s*$ipAddress\s*\|\s*.+\s*\|\s*$countryCode\s*\|\s*.+\s*\|$freeText0$
# parser.lineRegExp=


##
# UI
##

# Default country code
ui.organizationHandler.defaultCountryCode=SE
# Default language code
ui.organizationHandler.defaultLanguageCode=sv
# Path to export files
ui.organizationHandler.outputFilePath=/tmp/ui-org
# Organization contact roles e.g Abuse, Technical, Manager.
ui.organizationHandler.validRoles=Abuse, Technical, Administrative, Manager
# Default timestamp format
ui.organizationHandler.timestampFormat=yyyy-MM-dd HH:mm:ss z
